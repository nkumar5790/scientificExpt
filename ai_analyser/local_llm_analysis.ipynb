{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ee0bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nomic in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain_community in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: tiktoken in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: langchainhub in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.1.20)\n",
      "Requirement already satisfied: chromadb in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.5.3)\n",
      "Requirement already satisfied: langchain in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: langgraph in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: nomic[local] in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (3.0.33)\n",
      "Collecting nomic[local]\n",
      "  Downloading nomic-3.0.34.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m328.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.1.46 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain-nomic) (0.2.9)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain-nomic) (10.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (0.1.81)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain_community) (8.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchainhub) (23.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchainhub) (2.32.0.20240622)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (2.5.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (1.18.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (1.60.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (3.10.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: click in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (8.1.7)\n",
      "Requirement already satisfied: jsonlines in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (0.7.2)\n",
      "Requirement already satisfied: rich in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (13.7.0)\n",
      "Requirement already satisfied: pandas in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (2.0.3)\n",
      "Requirement already satisfied: pyarrow in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (16.1.0)\n",
      "Requirement already satisfied: pyjwt in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (2.8.0)\n",
      "Requirement already satisfied: gpt4all<3,>=2.5.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from nomic[local]) (2.7.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (3.1.3)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (2.2.0)\n",
      "Requirement already satisfied: anyio in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (1.33)\n",
      "Requirement already satisfied: coloredlogs in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.2)\n",
      "Requirement already satisfied: sympy in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (70.0.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from rich->nomic[local]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from rich->nomic[local]) (2.17.2)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from pandas->nomic[local]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from pandas->nomic[local]) (2023.4)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->nomic[local]) (0.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/nishantkumar/PycharmProjects/scientificProject/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Building wheels for collected packages: nomic\n",
      "  Building wheel for nomic (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nomic: filename=nomic-3.0.34-py3-none-any.whl size=44345 sha256=9c04d7e18f4e28cb20abd0f8da04ddc7ad96037f1d5877962bfc4fcfbbfa27e2\n",
      "  Stored in directory: /Users/nishantkumar/Library/Caches/pip/wheels/94/e2/dd/effe5c2df192f1143aefa6e17b6bf779fdce12dfe71f839b01\n",
      "Successfully built nomic\n",
      "Installing collected packages: nomic\n",
      "  Attempting uninstall: nomic\n",
      "    Found existing installation: nomic 3.0.33\n",
      "    Uninstalling nomic-3.0.33:\n",
      "      Successfully uninstalled nomic-3.0.33\n",
      "Successfully installed nomic-3.0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 46 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.18-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.17-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.16-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.15-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.14-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.13-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.12-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.11-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 665 kB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.10-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.8-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading chromadb-0.3.7-py3-none-any.whl (39 kB)\n",
      "  Downloading chromadb-0.3.6-py3-none-any.whl (39 kB)\n",
      "  Downloading chromadb-0.3.5-py3-none-any.whl (38 kB)\n",
      "  Downloading chromadb-0.3.4-py3-none-any.whl (38 kB)\n",
      "  Downloading chromadb-0.3.3-py3-none-any.whl (38 kB)\n",
      "  Downloading chromadb-0.3.2-py3-none-any.whl (37 kB)\n",
      "Collecting uvicorn[standard]~=0.18.3\n",
      "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting duckdb~=0.5.1\n",
      "  Downloading duckdb-0.5.1-cp38-cp38-macosx_10_9_x86_64.whl (15.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.9 MB 1.8 MB/s eta 0:00:01     |███████████████████████         | 11.4 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastapi~=0.85.1\n",
      "  Downloading fastapi-0.85.2-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentence-transformers~=2.2.2\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "Collecting numpy<2,>=1\n",
      "  Downloading numpy-1.21.6-cp38-cp38-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clickhouse-connect~=0.5.7\n",
      "  Downloading clickhouse_connect-0.5.25-cp38-cp38-macosx_10_9_x86_64.whl (236 kB)\n",
      "\u001b[K     |████████████████████████████████| 236 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Downloading chromadb-0.3.1-py3-none-any.whl (37 kB)\n",
      "  Downloading chromadb-0.3.0-py3-none-any.whl (36 kB)\n",
      "  Downloading chromadb-0.2.0-py3-none-any.whl (36 kB)\n",
      "Collecting uuid~=1.30\n",
      "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.1.0-py3-none-any.whl (34 kB)\n",
      "INFO: pip is looking at multiple versions of langchainhub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.19-py3-none-any.whl (5.0 kB)\n",
      "Collecting packaging<25.0,>=24.1\n",
      "  Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.18-py3-none-any.whl (4.8 kB)\n",
      "  Downloading langchainhub-0.1.17-py3-none-any.whl (4.8 kB)\n",
      "INFO: pip is looking at multiple versions of starlette to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchainhub-0.1.16-py3-none-any.whl (4.8 kB)\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "  Downloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "  Downloading langchainhub-0.1.13-py3-none-any.whl (3.4 kB)\n",
      "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of langchainhub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchainhub-0.1.12-py3-none-any.whl (3.4 kB)\n",
      "  Downloading langchainhub-0.1.11-py3-none-any.whl (3.4 kB)\n",
      "  Downloading langchainhub-0.1.10-py3-none-any.whl (3.4 kB)\n",
      "  Downloading langchainhub-0.1.9-py3-none-any.whl (3.2 kB)\n",
      "  Downloading langchainhub-0.1.8-py3-none-any.whl (3.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "  Downloading langchainhub-0.1.7-py3-none-any.whl (2.9 kB)\n",
      "  Downloading langchainhub-0.1.6-py3-none-any.whl (2.9 kB)\n",
      "  Downloading langchainhub-0.1.5-py3-none-any.whl (2.9 kB)\n",
      "  Downloading langchainhub-0.1.4-py3-none-any.whl (2.8 kB)\n",
      "  Downloading langchainhub-0.1.3-py3-none-any.whl (2.8 kB)\n",
      "  Downloading langchainhub-0.1.2-py3-none-any.whl (2.6 kB)\n",
      "  Downloading langchainhub-0.1.1-py3-none-any.whl (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of tiktoken to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.6.0-cp38-cp38-macosx_10_9_x86_64.whl (975 kB)\n",
      "  Downloading tiktoken-0.5.2-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.5.1-cp38-cp38-macosx_10_9_x86_64.whl (953 kB)\n",
      "\u001b[K     |████████████████████████████████| 953 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.5.0-cp38-cp38-macosx_10_9_x86_64.whl (955 kB)\n",
      "\u001b[K     |████████████████████████████████| 955 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.4.0-cp38-cp38-macosx_10_9_x86_64.whl (798 kB)\n",
      "\u001b[K     |████████████████████████████████| 798 kB 412 kB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.3.3-cp38-cp38-macosx_10_9_x86_64.whl (736 kB)\n",
      "\u001b[K     |████████████████████████████████| 736 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.3.2-cp38-cp38-macosx_10_9_x86_64.whl (735 kB)\n",
      "\u001b[K     |████████████████████████████████| 735 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tiktoken to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tiktoken-0.3.1-cp38-cp38-macosx_10_9_x86_64.whl (734 kB)\n",
      "\u001b[K     |████████████████████████████████| 734 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.3.0-cp38-cp38-macosx_10_9_x86_64.whl (734 kB)\n",
      "\u001b[K     |████████████████████████████████| 734 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blobfile>=2\n",
      "  Downloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tiktoken\n",
      "  Downloading tiktoken-0.2.0-cp38-cp38-macosx_10_9_x86_64.whl (729 kB)\n",
      "\u001b[K     |████████████████████████████████| 729 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading tiktoken-0.1.2-cp38-cp38-macosx_10_9_x86_64.whl (728 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 728 kB 847 kB/s eta 0:00:01\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain\n",
      "  Downloading langchain-0.2.4-py3-none-any.whl (974 kB)\n",
      "\u001b[K     |████████████████████████████████| 974 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Using cached langchain-0.2.3-py3-none-any.whl (974 kB)\n",
      "  Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n",
      "\u001b[K     |████████████████████████████████| 973 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
      "\u001b[K     |████████████████████████████████| 973 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
      "\u001b[K     |████████████████████████████████| 973 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# !{sys.executable} -m pip install  \"unstructured[all-docs]\"\n",
    "# !{sys.executable} -m pip install  unstructured \n",
    "# !{sys.executable} -m pip install  unstructured langchain\n",
    "# !{sys.executable} -m pip install  \"unstructured[all-docs]\"\n",
    "\n",
    "!{sys.executable} -m pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph \"nomic[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d4b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# importing required classes \n",
    "from pypdf import PdfReader \n",
    "\n",
    "# creating a pdf reader object \n",
    "reader = PdfReader(\"WEF_The_Global_Cooperation_Barometer_2024.pdf\") \n",
    "\n",
    "# printing number of pages in pdf file \n",
    "print(len(reader.pages)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a837caf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "docs_list = []\n",
    "for i in range(len(reader.pages)):\n",
    "    print(i)\n",
    "    # creating a page object \n",
    "    page = reader.pages[i] \n",
    "\n",
    "    # extracting text from page \n",
    "    docs_list.append(page.extract_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8276f9f-4a57-4a2a-8cd3-7aeeb555c9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Global Cooperation \\nBarometer 2024\\nINSIGHT REPORT\\nJANUARY 2024In collaboration with \\nMcKinsey & Company'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955fae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "# urls = [\n",
    "#     \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "#     \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "#     \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "# ]\n",
    "\n",
    "# docs = [WebBaseLoader(url).load() for url in urls]\n",
    "# docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "\n",
    "# doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "doc_splits = text_splitter.create_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9646c-8d14-4e0a-af59-0c551d9cde44",
   "metadata": {},
   "source": [
    "### Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686a4194-871b-4241-857b-8132fe7ded6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "local_llm = \"llama2\"\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"global cooperation barometer\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40e827-fddc-473c-a565-ef887812e5cf",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea7cd26-cb03-4a55-a518-808a485fda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Global Cooperation Barometer is a tool used to measure the level of cooperation among nations and economies in various areas, including trade and capital, innovation and technology, climate and natural capital, health and wellness, and peace and security. The barometer identifies goals that actors are working towards in each of these themes and quantifies change in these pillars using 42 indicators. These indicators measure cooperative actions that provide evidence of real, manifested cooperation, such as flows of goods and exchange of intellectual property, as well as outcome metrics such as life expectancy. By providing a structured framework for analyzing global cooperation, the barometer aims to inspire and guide cooperative efforts among nations and economies towards achieving sustainable development goals.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f0fe6-ec48-43b4-a4de-4a4ef3eb5368",
   "metadata": {},
   "source": [
    "### Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e85dbe-04c6-41c7-aab6-86be8d2e44de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n",
    "\n",
    "### Answer Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f557c13d-31d6-480e-9e55-e73977fd4027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is useful to resolve a question. \\n \n",
    "    Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question}\n",
    "    Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f162cf5-7251-4765-bc8e-b78b4c1af0f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f68ef255-ba51-4927-99a8-fc1ea34dc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Router\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# # LLM\n",
    "# llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "#     user question to a vectorstore or web search. Use the vectorstore for questions on LLM  agents, \n",
    "#     prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \n",
    "#     in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "#     or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "#     no premable or explanation. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "#     input_variables=[\"question\"],\n",
    "# )\n",
    "\n",
    "# question_router = prompt | llm | JsonOutputParser()\n",
    "# question = \"what is golbal cooperation barometer\"\n",
    "# docs = retriever.get_relevant_documents(question)\n",
    "# doc_txt = docs[1].page_content\n",
    "# print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e788db37-faf6-4752-979f-1cd517273500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, I\\'d be happy to help! Based on the initial question you provided, here\\'s an improved version that could potentially perform better in a vector store retrieval context:\\n\\n\"Cooperation Barometer: Global Trends and Insights\"\\n\\nIn this revised question, we\\'ve removed unnecessary words and phrases, simplified the language, and added more specific keywords related to cooperation and global trends. This should make it easier for a vector store algorithm to retrieve relevant information when searching for answers to this question.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Prompt\n",
    "re_write_prompt = PromptTemplate(\n",
    "    template=\"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the initial and formulate an improved question. \\n\n",
    "     Here is the initial question: \\n\\n {question}. Improved question with no preamble: \\n \"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb0a541-09a4-44d6-b61c-c43276232223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3cd3c97-a7ea-434f-8942-fc12d3339537",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b64486-e207-4d35-a125-d5ee86eceb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291f478-718a-4127-91ea-1e723188d653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"Explain what is global cooperation barometer?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77cdb4-f670-4ea1-8406-b70d4a7b59f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-venv",
   "language": "python",
   "name": "sci-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
